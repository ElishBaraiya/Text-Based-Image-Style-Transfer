# ğŸ¨ DIB-TIST: Dynamic Image Blending for Enhancement of Text-based Image Style Transfer

Official implementation of our **CVIP 2025** paper:  
**"DIB-TIST: Dynamic Image Blending for Enhancement of Text-based Image Style Transfer"**

## ğŸ“‘ Paper
ğŸ“„ [Read the paper (PDF)](paper/DBIST_CVIP_2025.pdf)

---

## ğŸ“„ Abstract
Text-based image style transfer (TIST) enables users to define styles through natural language descriptions.  
However, existing methods like **MMIST** often struggle with **foreground-background separation**, resulting in blurred edges.  

We propose **DIB-TIST**, a novel method that dynamically blends content features into the stylized output using a **contextual-lossâ€“based adaptive weight**.  
This improves structural preservation while maintaining artistic fidelity.  

ğŸ“Š Our method achieved:
- **SSIM = 0.606**  
- **GMD = 0.394**  
on the Flickr30k benchmark, outperforming MMIST.

---

## ğŸš€ Key Contributions
- ğŸ”¹ Dynamic blend-weight controlled by contextual loss  
- ğŸ”¹ Improved edge preservation in stylized outputs  
- ğŸ”¹ Extensive experiments with multiple text-driven styles  
- ğŸ”¹ Open-source implementation with reproducible results  

---

## ğŸ” Motivation
Existing **MMIST** outputs often suffer from blurred edges and weak foreground-background separation:  

<p align="center">
  <img src="examples/newyork_mmist.png" width="80%">
</p>

*Left: Content Image | Right: MMIST Output (blurred edges highlighted)*

---

## ğŸ“Š Results: Hyperparameter tuning (Î» values)
<p align="center">
  <img src="examples/tunning_image_2.png" width="85%">
</p>
